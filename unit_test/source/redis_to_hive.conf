env {
  spark.streaming.batchDuration = 5
  spark.app.name = "seatunnel"
  spark.ui.port = 13000
  spark.sql.catalogImplementation = "hive"
}

source {
  redis {
    host = "localhost"
    port = 6379
    auth = "myPassword"
    db_num = 1
    keys_or_key_pattern = "*"
    partition_num = 20
    data_type = "HASH"
    result_table_name = "hash_result_table"
  }
}

transform {
}

sink {
  console{
  }
//  Hive {
//    source_table_name = "test_druid_to_hive"
//    result_table_name = "user_85`.`test_druid_to_hive"
//    save_mode = "overwrite"
//    sink_columns = "name,age,detail,address"
//  }
}