env {
  spark.streaming.batchDuration = 5
  spark.app.name = "seatunnel"
  spark.ui.port = 13000
  spark.sql.catalogImplementation = "hive"
}

source {
  Hbase {
    hbase.zookeeper.quorum = "localhost:2181"
    catalog = "{\"table\":{\"namespace\":\"default\", \"name\":\"test\"},\"rowkey\":\"id\",\"columns\":{\"id\":{\"cf\":\"rowkey\", \"col\":\"id\", \"type\":\"string\"},\"a\":{\"cf\":\"f1\", \"col\":\"a\", \"type\":\"string\"},\"b\":{\"cf\":\"f1\", \"col\":\"b\", \"type\":\"string\"},\"c\":{\"cf\":\"f1\", \"col\":\"c\", \"type\":\"string\"}}}"
    result_table_name = "my_dataset"
  }
}

transform {
}

sink {
  console{
  }
//  Hive {
//    source_table_name = "test_druid_to_hive"
//    result_table_name = "user_85`.`test_druid_to_hive"
//    save_mode = "overwrite"
//    sink_columns = "name,age,detail,address"
//  }
}