env {
  spark.streaming.batchDuration = 5
  spark.app.name = "seatunnel"
  spark.ui.port = 13000
  spark.sql.catalogImplementation = "hive"
}

source {
  elasticsearch {
      hosts = ["192.168.50.25:9200"]
      index = "test_index"
      es.nodes.wan.only = true
      result_table_name = "test_es_to_hive"
  }
}

transform {
}

sink {
  Hive {
    source_table_name = "test_es_to_hive"
    result_table_name = "test_es_to_hive"
    save_mode = "overwrite"
  }
}